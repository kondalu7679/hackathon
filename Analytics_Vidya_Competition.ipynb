{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas    as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder,CategoricalEncoder,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y.pickle','rb') as f:\n",
    "    y = pickle.load(f)\n",
    "    \n",
    "with open('word_vetor.pickle','rb') as f:\n",
    "    word_vector = pickle.load(f)\n",
    "    \n",
    "with open('test_data.pickle','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\train_8wry4cB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start'] = data['startTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "data['end'] = data['endTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "data['session_time'] = data['end']-data['start']\n",
    "\n",
    "def change_to_minutes(st):\n",
    "    data_list = str(st).split(':')\n",
    "    return int(data_list[1])+int(data_list[2])/60\n",
    "data['duration'] = data['session_time'].apply(change_to_minutes)\n",
    "data.drop(data.iloc[:,[0,1,2,5,6,7]],axis=1,inplace=True)\n",
    "\n",
    "products = []\n",
    "ind_prds = []\n",
    "for dt in data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    \n",
    "    products.extend(lst)\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        ind_prds.extend(sd)\n",
    "    #print(dt)\n",
    "for ls in ind_prds:\n",
    "    if ls=='':\n",
    "        ind_prds.remove('')   \n",
    "        \n",
    "y= data['gender']\n",
    "word_dict = {}\n",
    "for word in ind_prds:\n",
    "    if word in word_dict:\n",
    "        word_dict[word] +=1\n",
    "    else:\n",
    "        word_dict[word] = 1\n",
    "word_final = dict(sorted(word_dict.items(),key=lambda x:x[1],reverse=True)[:3750])\n",
    "\n",
    "vocab = {}\n",
    "i=0 \n",
    "for word in word_final.keys():\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word] = i\n",
    "        i +=1\n",
    "#print(vocab)\n",
    "total_list = []\n",
    "for dt in data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    inner_list = []\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        inner_list.extend(sd)\n",
    "    total_list.append(inner_list)\n",
    " \n",
    "\n",
    "word_vector = []\n",
    "for line in total_list:\n",
    "    lexicon2 = [0]*len(vocab.keys())\n",
    "    for word in line:\n",
    "        \n",
    "        if word in vocab:\n",
    "            #print(vocab[word])\n",
    "            \n",
    "            lexicon2[vocab[word]] =1\n",
    "            \n",
    "    #print(lexicon2)\n",
    "    word_vector.append(lexicon2)\n",
    "for w,d in zip(word_vector,data['duration']):\n",
    "    w.append(d)    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('word_vetor.pickle','wb') as f:\n",
    "    pickle.dump(word_vector,f)\n",
    "with open('y.pickle','wb') as f:\n",
    "    pickle.dump(y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vector[0][3750]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\test_Yix80N0.csv')\n",
    "\n",
    "test_data['start'] = test_data['startTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "test_data['end'] = test_data['endTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "test_data['session_time'] = test_data['end']-test_data['start']\n",
    "def change_to_minutes(st):\n",
    "    data_list = str(st).split(':')\n",
    "    return int(data_list[1])+int(data_list[2])/60\n",
    "test_data['duration'] = test_data['session_time'].apply(change_to_minutes)\n",
    "ID = test_data['session_id']\n",
    "test_data.drop(test_data.iloc[:,[0,1,2,4,5,6]],axis=1,inplace=True)\n",
    "\n",
    "test_list = []\n",
    "for dt in test_data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    inner_list = []\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        inner_list.extend(sd)\n",
    "    test_list.append(inner_list)\n",
    "    \n",
    "test_vector = []\n",
    "for line in test_list:\n",
    "    lexicon2 = [0]*len(vocab.keys())\n",
    "    for word in line:\n",
    "        \n",
    "        if word in vocab:\n",
    "            #print(vocab[word])\n",
    "            \n",
    "            lexicon2[vocab[word]] =1\n",
    "            \n",
    "    #print(lexicon2)\n",
    "    test_vector.append(lexicon2)\n",
    "\n",
    "for w,d in zip(test_vector,test_data['duration']):\n",
    "    w.append(d)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('test_data.pickle','wb') as f:\n",
    "    pickle.dump(test_vector,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)\n",
    "test_vector[0][3750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier,voting_classifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#submission = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\sample_submission_opxHi4g.csv')\n",
    "#y_test = submission['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8943809523809524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logis = LogisticRegression()\n",
    "logis.fit(word_vector,y)\n",
    "predictions_logis = logis.predict(word_vector)\n",
    "accuracy_score(logis.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5097777777777778"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = logis.predict(test_vector)\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8786666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(word_vector,y)\n",
    "predictions_MNB = MNB.predict(word_vector)\n",
    "accuracy_score(MNB.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5117777777777778"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = MNB.predict(test_vector)\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8833333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD = SGDClassifier()\n",
    "SGD.fit(word_vector,y)\n",
    "predictions_SGD = SGD.predict(word_vector)\n",
    "accuracy_score(SGD.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9235238095238095"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC = LinearSVC()\n",
    "LSVC.fit(word_vector,y)\n",
    "predictions_LSVC = LSVC.predict(word_vector)\n",
    "accuracy_score(LSVC.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5055555555555555"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = LSVC.predict(test_vector)\n",
    "accuracy_score(predict,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9393333333333334"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(word_vector,y)\n",
    "predictions_RFC = RFC.predict(word_vector)\n",
    "accuracy_score(RFC.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('RFC.pickle','wb') as f:\n",
    "    pickle.dump(RFC,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8783809523809524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ABC = AdaBoostClassifier()\n",
    "ABC.fit(word_vector,y)\n",
    "predictions_ABC = ABC.predict(word_vector)\n",
    "accuracy_score(ABC.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging = BaggingClassifier()\n",
    "bagging.fit(word_vector,y)\n",
    "predictions_bagging = bagging.predict(word_vector)\n",
    "accuracy_score(bagging.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('bagging.pickle','wb') as f:\n",
    "    pickle.dump(bagging,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8792380952380953"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "GBC.fit(word_vector,y)\n",
    "predictions = GBC.predict(word_vector)\n",
    "accuracy_score(GBC.predict(word_vector),y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions_bagging = bagging.predict(test_data)\n",
    "predictions_RFC = RFC.predict(test_data)\n",
    "predictions_LSVC = LSVC.predict(test_data)\n",
    "predictions_logis =logis.predict(test_data)\n",
    "predictions_SGD =SGD.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,KFold,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param ={'n_estimators':[10,50,100],'criterion':['gini'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ = RandomizedSearchCV(estimator=RandomForestClassifier(),param_distributions=param,n_iter=10,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:271: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "RZ.fit(word_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RZ_pred = RZ.predict(word_vector)\n",
    "accuracy_score(RZ_pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN.fit(word_vector,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884761904761905"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_pred = KNN.predict(word_vector)\n",
    "accuracy_score(KNN_pred,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_data = pd.DataFrame({'predictions_bagging':predictions_bagging,\n",
    "                             'predictions_LSVC':predictions_LSVC,'predictions_SGD':predictions_SGD,'predictions_logis':predictions_logis,\n",
    "                            'predictions_RFC':predictions_RFC,'predictions_ABC':predictions_ABC,'predictions_MNB':predictions_MNB,})\n",
    "from statistics import mode\n",
    "result = []\n",
    "for i in range(len(predict_data)):\n",
    "    result.append(mode(predict_data.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9213333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(result,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bagging = bagging.predict(test_data)\n",
    "predictions_RFC = RFC.predict(test_data)\n",
    "predictions_LSVC = LSVC.predict(test_data)\n",
    "predictions_logis =logis.predict(test_data)\n",
    "predictions_SGD =SGD.predict(test_data)\n",
    "\n",
    "\n",
    "predict_data = pd.DataFrame({'predictions_bagging':predictions_bagging,\n",
    "                             'predictions_LSVC':predictions_LSVC,'predictions_SGD':predictions_SGD,'predictions_logis':predictions_logis,\n",
    "                            'predictions_RFC':predictions_RFC})\n",
    "from statistics import mode\n",
    "result = []\n",
    "for i in range(len(predict_data)):\n",
    "    result.append(mode(predict_data.iloc[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'female',\n",
       " 'male',\n",
       " 'male',\n",
       " 'male',\n",
       " 'female',\n",
       " 'male']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\test_Yix80N0.csv')\n",
    "ID = t['session_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(predictions_RFC,y))\n",
    "print(classification_report(predictions_RFC,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'G:\\DATASETS\\Analytics Vidya\\submission_vote.csv'\n",
    "submission = pd.DataFrame({'session_id':ID,'gender':result})\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas    as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\train_8wry4cB.csv')\n",
    "#converting object data field into date formate\n",
    "data['start'] = data['startTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "data['end'] = data['endTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "## duration time in the time formate\n",
    "data['session_time'] = data['end']-data['start']\n",
    "# function for changing duration values to minutes int type\n",
    "def change_to_minutes(st):\n",
    "    data_list = str(st).split(':')\n",
    "    return int(data_list[1])+int(data_list[2])/60\n",
    "data['duration'] = data['session_time'].apply(change_to_minutes)\n",
    "#dropping extra columns \n",
    "data.drop(data.iloc[:,[0,1,2,5,6,7]],axis=1,inplace=True)\n",
    "\n",
    "products = []   # set of products \n",
    "ind_prds = []   # all product names\n",
    "for dt in data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    \n",
    "    products.extend(lst)\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        ind_prds.extend(sd)\n",
    "    #print(dt)\n",
    "for ls in ind_prds:\n",
    "    if ls=='':\n",
    "        ind_prds.remove('')   \n",
    "#dependent variable       \n",
    "y= data['gender']\n",
    "# find the most repated products \n",
    "word_dict = {}\n",
    "for word in ind_prds:\n",
    "    if word in word_dict:\n",
    "        word_dict[word] +=1\n",
    "    else:\n",
    "        word_dict[word] = 1\n",
    "#selecting 3750 most repeated products.     \n",
    "word_final = dict(sorted(word_dict.items(),key=lambda x:x[1],reverse=True)[:3750])\n",
    "# giving ranking to the selected products from the above\n",
    "vocab = {}\n",
    "i=0 \n",
    "for word in word_final.keys():\n",
    "    if word in vocab:\n",
    "        continue\n",
    "    else:\n",
    "        vocab[word] = i\n",
    "        i +=1\n",
    "#train data is converting to word vectors by splitting the products in each line\n",
    "total_list = []\n",
    "for dt in data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    inner_list = []\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        inner_list.extend(sd)\n",
    "    total_list.append(inner_list)\n",
    "#training vector ...word vector to binary vector\n",
    "train_vector = []\n",
    "for line in total_list:\n",
    "    lexicon2 = [0]*len(vocab.keys())\n",
    "    for word in line:\n",
    "        if word in vocab:\n",
    "            lexicon2[vocab[word]] =1\n",
    "    train_vector.append(lexicon2)\n",
    "# appending duration column to correspodng binary vector\n",
    "for w,d in zip(train_vector,data['duration']):\n",
    "    w.append(d)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(r'G:\\DATASETS\\Analytics Vidya\\test_Yix80N0.csv')\n",
    "import datetime as dt\n",
    "test_data['start'] = test_data['startTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "test_data['end'] = test_data['endTime'].apply(lambda x:dt.datetime.strptime(x,\"%d/%m/%y %H:%M\"))\n",
    "test_data['session_time'] = test_data['end']-test_data['start']\n",
    "def change_to_minutes(st):\n",
    "    data_list = str(st).split(':')\n",
    "    return int(data_list[1])+int(data_list[2])/60\n",
    "test_data['duration'] = test_data['session_time'].apply(change_to_minutes)\n",
    "ID = test_data['session_id']\n",
    "test_data.drop(test_data.iloc[:,[0,1,2,4,5,6]],axis=1,inplace=True)\n",
    "\n",
    "test_list = []\n",
    "for dt in test_data['ProductList']:\n",
    "    lst = dt.split(';')\n",
    "    inner_list = []\n",
    "    for lst2 in lst:\n",
    "        sd = lst2.split('/')\n",
    "        inner_list.extend(sd)\n",
    "    test_list.append(inner_list)\n",
    "    \n",
    "test_vector = []\n",
    "for line in test_list:\n",
    "    lexicon2 = [0]*len(vocab.keys())\n",
    "    for word in line:\n",
    "        \n",
    "        if word in vocab:\n",
    "            #print(vocab[word])\n",
    "            \n",
    "            lexicon2[vocab[word]] =1\n",
    "            \n",
    "    #print(lexicon2)\n",
    "    test_vector.append(lexicon2)\n",
    "\n",
    "for w,d in zip(test_vector,test_data['duration']):\n",
    "    w.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "votingom sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy              0.8939047619047619\n",
      "SGDClassifier Accuracy                   0.9082857142857143\n",
      "LinearSVC Accuracy                       0.9237142857142857\n",
      "RandomForestClassifier Accuracy          0.947047619047619\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logis = LogisticRegression()\n",
    "logis.fit(train_vector,y)\n",
    "predictions_logis = logis.predict(train_vector)\n",
    "print(f'{\"LogisticRegression Accuracy \":<{40}} {accuracy_score(predictions_logis,y)}')\n",
    "\n",
    "SGD = SGDClassifier()\n",
    "SGD.fit(train_vector,y)\n",
    "predictions_SGD = SGD.predict(train_vector)\n",
    "print(f'{\"SGDClassifier Accuracy \":<{40}} {accuracy_score(predictions_SGD,y)}')\n",
    "\n",
    "LSVC = LinearSVC()\n",
    "LSVC.fit(train_vector,y)\n",
    "predictions_LSVC = LSVC.predict(train_vector)\n",
    "print(f'{\"LinearSVC Accuracy \":<{40}} {accuracy_score(predictions_LSVC,y)}')\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "RFC.fit(train_vector,y)\n",
    "predictions_RFC = RFC.predict(train_vector)\n",
    "print(f'{\"RandomForestClassifier Accuracy \":<{40}} {accuracy_score(predictions_RFC,y)}')\n",
    "\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(train_vector,y)\n",
    "predictions_bagging = bagging.predict(train_vector)\n",
    "print(f'{\"BaggingClassifier Accuracy \":<{40}} {accuracy_score(predictions_bagging,y)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_bagging = bagging.predict(test_vector)\n",
    "predictions_RFC = RFC.predict(test_vector)\n",
    "predictions_LSVC = LSVC.predict(test_vector)\n",
    "predictions_logis =logis.predict(test_vector)\n",
    "predictions_SGD =SGD.predict(test_vector)\n",
    "\n",
    "\n",
    "predict_data = pd.DataFrame({'predictions_bagging':predictions_bagging,\n",
    "                             'predictions_LSVC':predictions_LSVC,'predictions_SGD':predictions_SGD,'predictions_logis':predictions_logis,\n",
    "                            'predictions_RFC':predictions_RFC})\n",
    "from statistics import mode\n",
    "result = []\n",
    "for i in range(len(predict_data)):\n",
    "    result.append(mode(predict_data.iloc[i]))\n",
    "    \n",
    "filename = r'submission_vote.csv'\n",
    "submission = pd.DataFrame({'session_id':ID,'gender':result})\n",
    "submission.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u12112</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u19725</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u11795</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u22639</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u18034</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  session_id  gender\n",
       "0     u12112  female\n",
       "1     u19725  female\n",
       "2     u11795  female\n",
       "3     u22639  female\n",
       "4     u18034  female"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
